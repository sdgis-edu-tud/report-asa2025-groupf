# Typology Construction

## Introduction

This tutorial demonstrates how to construct urban typologies in R. Specifically, we use K-means Clustering, a method of unsupervised machine learning, to classify urban units into typologies for urban stream restoration.

### Preparation

In the previous session, we introduced the key preparatory steps for typology construction before clustering. Here, we provide a specific example that illustrates how these steps can be applied in a particular context.

-   **Define your objective**:\
    TODO
-   **Define your focused area**:\
    The space around the stream corridors in the whole city of Dresden.
-   **Define your spatial unit**:\
    TODO
-   **Define your variables**:
    - TODO
    - TODO
    - TODO

## Clustering steps

After the above preparatory steps, now we start the clustering process.

We will:

- Step 1. Load R packages and data
- Step 2. Standardization
- Step 3. Determine optimal k
- Step 4. Run K-means clustering
- Step 5. Interpret cluster center
- Step 6. (Optional) Calculate distance to cluster center

### Step 1. Load R packages and data

We begin by loading the necessary R packages.

If you haven't installed these packages yet, remove the `#` and run the following chunk before continuing:

```{r}
#| output: false
#install.packages("sf") 
#install.packages("dplyr")

library(sf) ## for processing vector data 
library(dplyr) ## for selecting and transforming data
library(plotly) ## for plotting data
```

```{r}
spatial_units <- st_read("../data/results/Spatial_Units-All_Attributes.geojson", quiet = TRUE)

## View the columns of the data
colnames(spatial_units)

## Count how many spatial units we have
nrow(spatial_units)
```

Then select the columns to use:

```{r}
used_attributes <- c(
  Green_Area = "Green area",
  Space_along_Streams = "Space along Streams",
  Shade_3pm = "Shade at 3pm",
  Accessibility = "Accessibility to streams"
)
n_attr <- length(used_attributes)
```

We can also visualize the data to have a better understanding visually.

```{r}
#| layout-ncol: 2

## Plot the attributes in two columns
for (col in names(used_attributes)) {
     plot(spatial_units[col], border = NA, main = used_attributes[[col]])
}
```

### Step 2. Standardization

We select the relevant features. These features are then standardized to ensure they contribute equally to the clustering algorithm.

```{r}
features <- spatial_units |> 
  select(names(used_attributes)) |>
  st_drop_geometry() ## remove geometry column so we just keep a data table

X_scaled <- scale(features) ## Standardize (mean=0, sd=1) 

head(X_scaled)
```

### Step 3: Determine the optimal K

We use the **elbow method** to choose a good number of clusters.

For each value of `k` (e.g. 2 to 9), we run K-means and record a value called **inertia** : the total distance between points and their cluster centers. Lower inertia means tighter (better) clusters.

```{r}
## Initialize an empty numeric vector to store inertia values 
inertia <- numeric()

## Try k values from 2 to 9
k_values <- 2:9

## Loop through each k value
for (k in k_values) {
  km <- kmeans(X_scaled, centers = k, iter.max=25, nstart = 50) 
  
  ## tot.withinss is Total within-cluster sum of squares
  ## This measures how compact the clusters are: lower is better.
  inertia <- c(inertia, km$tot.withinss)
}

## Combine the results into a data frame for plotting
elbow_df <- data.frame(k = k_values, inertia = inertia)

# print(elbow_df)
```

We can visualize how inertia changes with increasing k. After a certain point, adding more clusters doesn’t help much — the curve bends. That bend is called the *elbow point*, and we use it to choose the best k.

```{r}
## Make the elbow plot
plot(k_values, inertia,
     type = "b",
     col = "darkblue",
     main = "Elbow Method")
```

### Step 4. Run K-Means clustering

Based on the elbow plot, we choose `k = 4` as a good number of clusters.\
We now run the K-means algorithm and assign each grid to one of the four clusters.

```{r}
## `set.seed()` sets the random number generator to a fixed state
## Set the seed so the clustering result is always the same when re-run
set.seed(0)  ## The number 0 is just a fixed choice. You can also use 10, 345, etc.

## Choose the number of clusters based on the elbow plot
n_clusters <- 4

# Run K-means clustering on the standardized data
kmeans_result <- kmeans(X_scaled, centers = n_clusters, nstart = 20)

# # You can use Gaussian Mixture Models (GMM) via the 'mclust' package
# # install.packages("mclust") # Uncomment if not installed
# library(mclust)

# # Fit a GMM with 4 components (clusters)
# gmm_result <- Mclust(X_scaled, G = n_clusters)

# # Assign cluster labels from GMM
# kmeans_result <- list(
#      cluster = gmm_result$classification,
#      centers = gmm_result$parameters$mean[, 1:n_clusters, drop = FALSE]
# )

## Add the cluster labels to the spatial data
spatial_units$Cluster <- as.factor(kmeans_result$cluster) ## The result kmeans_result$cluster is a list of cluster labels (1 to 4), in the same order as the original rows in X_scaled and spatial_units

colnames(spatial_units)

## Show how many spatial_units fall into each cluster
print(table(spatial_units$Cluster))
```

Save the updated grid data (with cluster labels) to a new GeoPackage file. You can use it for further analysis and visualize.

```{r}
#st_write(spatial_units, "spatial_units.gpkg")
```

We can also visualize the spatial pattern.

```{r}
## Generate cluster colors dynamically
cluster_levels <- levels(spatial_units$Cluster)
cluster_colors_all <- palette.colors(palette = "Okabe-Ito")
cluster_colors <- setNames(cluster_colors_all[seq_len(n_clusters)], cluster_levels)

## Plot clusters with base R
plot(spatial_units["Cluster"], 
     main = "Spatial Pattern of Urban Stream Clusters", 
     border = NA,
     col = cluster_colors[spatial_units$Cluster])

legend("topright",
     legend = levels(spatial_units$Cluster),
     fill = cluster_colors,
     title = "Cluster",
     cex = 0.9,
     bty = "n")
```

### Step 5. Interpret cluster centers

Now we look at the center of each cluster. First, we check the values in standardized form. Then, we convert them back to the original units (e.g. degrees), so they are easier to understand.

```{r}
## Get the cluster centers (in standardized form)
scaled_centers <- kmeans_result$centers

## Convert the centers back to original scale: x * SD + mean
original_centers <- t(apply(
  scaled_centers, 1, 
  function(x) x * attr(X_scaled, "scaled:scale") + attr(X_scaled, "scaled:center")
))

## Print the real-world values
print(original_centers, digits=3)

```

To interpret the clustering results, we examine the centers of each cluster in the original data scale. The table below summarizes the environmental characteristics of each cluster based on the original (unscaled) values.

#### Typology description

| Type | Soil quality | Flood safety | Accessibility to streams | Description |
|---------|----------|---------|----------|--------------------|
| 1 | ??? | ??? | ??? | ........... |
| 2 | ??? | ??? | ??? | ........... |
| 3 | ??? | ??? | ??? | ........... |
| 4 | ??? | ??? | ??? | ........... |

### Step 6. (Optional) Calculate distance to cluster center

```{r}
### Step 6 (Optional): Compute distance to cluster center

## Get the cluster center for each row, using the cluster assignment
centroids_matrix <- kmeans_result$centers[kmeans_result$cluster, ]

## Calculate Euclidean distance between each point and its assigned cluster center
spatial_units_distances <- sqrt(rowSums((X_scaled - centroids_matrix)^2))

## Save to spatial_units
spatial_units$Cluster_Dist <- spatial_units_distances
st_write(spatial_units, "../data/results/Spatial_Units-Typology_Construction.geojson", delete_dsn = TRUE, quiet = TRUE)
```

## Summary

-   We prepared spatial data representing the surroundings of urban streams.
-   We selected key indicators for stream ecology: TODO.
-   We standardized the data to ensure fair clustering.
-   We used the elbow method to decide the K.
-   We performed K-means clustering to identify distinct urban stream types.
-   We analyzed and interpreted each cluster using cluster centers.
-   (Optional) We calculated how close each grid is to its cluster center.

This workflow can now be applied to your own datasets to explore meaningful typologies for planning and design. Enjoy clustering!

## Appendix

### A1. Visualize variable distributions in histogram

```{r}

## calculate nornalization
normalize <- function(x) (x - min(x)) / (max(x) - min(x))
features_norm <- as.data.frame(lapply(features, normalize))

## Set up color palette for any number of features (distinct colors)
set.seed(42) # for reproducibility
hist_colors <- grDevices::hcl.colors(n_attr, palette = "Dynamic", alpha = 1.0)

## Set canvas: 2 columns for original and standardized
par(mfrow = c(n_attr, 2), mar = c(4, 4, 2, 1))

## Plot histograms for each attribute
for (i in seq_along(used_attributes)) {
  colname <- names(used_attributes)[i]
  display <- used_attributes[[colname]]
  color <- hist_colors[i]

  # Original
  hist(features[[colname]],
       main = paste0(display, "\n(original)"),
       xlab = "value", col = color)

  # Standardized
  hist(X_scaled[, colname],
       main = paste0(display, "\n(standardized)"),
       xlab = "z-score", col = color)
}
```

### A2. K-means Euclidean distance

For a data point **`x`** with 3 variables ( `u, v, w` ),

$$
\mathbf{x} = (x_u, x_v, x_w)
$$\
and a cluster center\
$$
\mathbf{c} = (c_u, c_v, c_w),
$$\
the Euclidean distance between the point and the cluster center is calculated as:

$$
\text{Distance} = \sqrt{(x_u - c_u)^2 + (x_v - c_v)^2 + (x_w - c_w)^2}
$$

In our case:

:::{style="overflow-x:auto;overflow-y:hidden;"}
$$
\text{Distance} = \sqrt{
`r paste(
  sapply(names(used_attributes), function(col) {
    paste0(
      "(x_{\\text{", tolower(gsub("_", " ", col)), "}} - ",
      "c_{\\text{", tolower(gsub("_", " ", col)), "}})^2"
    )
  }),
  collapse = " +\n"
)`
}
$$
:::

### A3. Visualize cluster points in 3D distribution

```{r}
#| echo: false
#| title: 3D Distribution of the first 3 attributes
# Get the first three attribute names and display names
attr3_names <- names(used_attributes)[1:3]
attr3_display <- used_attributes[1:3]

cluster3d_scaled <- plot_ly(
  x = X_scaled[, attr3_names[1]],
  y = X_scaled[, attr3_names[2]],
  z = X_scaled[, attr3_names[3]],
  type = "scatter3d",
  mode = "markers",
  color = as.factor(kmeans_result$cluster),
  colors = cluster_colors,
  marker = list(size = 3)
) %>%
  layout(
    scene = list(
      xaxis = list(title = attr3_display[[1]]),
      yaxis = list(title = attr3_display[[2]]),
      zaxis = list(title = attr3_display[[3]])
    )
  )
cluster3d_scaled

```